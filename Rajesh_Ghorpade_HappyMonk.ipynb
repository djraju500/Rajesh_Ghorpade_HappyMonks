{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Dataset\n",
    "dataset = pd.read_csv ('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the Dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column names in the Dataset\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Columns information\n",
    "dataset.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 5 rows\n",
    "dataset.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING UNNEEDED FEATURES¶\n",
    "#The columns id and Unnamed: 32 don't play any role in the prediction and hence we can drop them from the dataset.\n",
    "dataset.drop ('id', axis = 1, inplace = True)\n",
    "dataset.drop ('Unnamed: 32', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the dataset\n",
    "dataset.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0        False        False         False           False      False   \n",
       "1        False        False         False           False      False   \n",
       "2        False        False         False           False      False   \n",
       "3        False        False         False           False      False   \n",
       "4        False        False         False           False      False   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564      False        False         False           False      False   \n",
       "565      False        False         False           False      False   \n",
       "566      False        False         False           False      False   \n",
       "567      False        False         False           False      False   \n",
       "568      False        False         False           False      False   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0              False             False           False                False   \n",
       "1              False             False           False                False   \n",
       "2              False             False           False                False   \n",
       "3              False             False           False                False   \n",
       "4              False             False           False                False   \n",
       "..               ...               ...             ...                  ...   \n",
       "564            False             False           False                False   \n",
       "565            False             False           False                False   \n",
       "566            False             False           False                False   \n",
       "567            False             False           False                False   \n",
       "568            False             False           False                False   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0            False  ...         False          False            False   \n",
       "1            False  ...         False          False            False   \n",
       "2            False  ...         False          False            False   \n",
       "3            False  ...         False          False            False   \n",
       "4            False  ...         False          False            False   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564          False  ...         False          False            False   \n",
       "565          False  ...         False          False            False   \n",
       "566          False  ...         False          False            False   \n",
       "567          False  ...         False          False            False   \n",
       "568          False  ...         False          False            False   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         False             False              False            False   \n",
       "1         False             False              False            False   \n",
       "2         False             False              False            False   \n",
       "3         False             False              False            False   \n",
       "4         False             False              False            False   \n",
       "..          ...               ...                ...              ...   \n",
       "564       False             False              False            False   \n",
       "565       False             False              False            False   \n",
       "566       False             False              False            False   \n",
       "567       False             False              False            False   \n",
       "568       False             False              False            False   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                   False           False                    False  \n",
       "1                   False           False                    False  \n",
       "2                   False           False                    False  \n",
       "3                   False           False                    False  \n",
       "4                   False           False                    False  \n",
       "..                    ...             ...                      ...  \n",
       "564                 False           False                    False  \n",
       "565                 False           False                    False  \n",
       "566                 False           False                    False  \n",
       "567                 False           False                    False  \n",
       "568                 False           False                    False  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING FOR MISSING DATA\n",
    "#Next we need to check for any missing data that might be present in the dataset. For this, we will be using the isna () function of the Pandas library\n",
    "dataset.isna ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the entries of the isna () function are false, we can conclude that there is no missing data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         unique count\n",
       "diagnosis                           2\n",
       "radius_mean                       456\n",
       "texture_mean                      479\n",
       "perimeter_mean                    522\n",
       "area_mean                         539\n",
       "smoothness_mean                   474\n",
       "compactness_mean                  537\n",
       "concavity_mean                    537\n",
       "concave points_mean               542\n",
       "symmetry_mean                     432\n",
       "fractal_dimension_mean            499\n",
       "radius_se                         540\n",
       "texture_se                        519\n",
       "perimeter_se                      533\n",
       "area_se                           528\n",
       "smoothness_se                     547\n",
       "compactness_se                    541\n",
       "concavity_se                      533\n",
       "concave points_se                 507\n",
       "symmetry_se                       498\n",
       "fractal_dimension_se              545\n",
       "radius_worst                      457\n",
       "texture_worst                     511\n",
       "perimeter_worst                   514\n",
       "area_worst                        544\n",
       "smoothness_worst                  411\n",
       "compactness_worst                 529\n",
       "concavity_worst                   539\n",
       "concave points_worst              492\n",
       "symmetry_worst                    500\n",
       "fractal_dimension_worst           535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECKING THE NUMBER OF UNIQUE VALUES\n",
    "#Next we will be checking how many unique values does each feature have, in order to get a much better understanding of the dataset we are working on.\n",
    "dict = {}\n",
    "for i in list(dataset.columns):\n",
    "    dict[i] = dataset[i].value_counts().shape[0]\n",
    "\n",
    "pd.DataFrame(dict,index=[\"unique count\"]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the above function we can see that we have only 1 categorical data feature and the rest are continuous data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODING THE CATEGORICAL VARIABLE\n",
    "To ensure that the entire dataset is of a continuous numerical form, we will be encoding the categorial variable DIAGNOSIS and converting into a numerical form, preferably into 0s and 1s.\n",
    "\n",
    "For this, we will be making use of the LabelEncoder class from the Preprocessing module of the Sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "5          1        12.45         15.70           82.57      477.1   \n",
       "6          1        18.25         19.98          119.60     1040.0   \n",
       "7          1        13.71         20.83           90.20      577.9   \n",
       "8          1        13.00         21.82           87.50      519.8   \n",
       "9          1        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "5         0.2087  ...         15.47          23.75           103.40   \n",
       "6         0.1794  ...         22.88          27.66           153.20   \n",
       "7         0.2196  ...         17.06          28.14           110.60   \n",
       "8         0.2350  ...         15.49          30.73           106.20   \n",
       "9         0.2030  ...         15.09          40.68            97.65   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y = LabelEncoder()\n",
    "dataset.diagnosis = labelencoder_Y.fit_transform(dataset.diagnosis)\n",
    "dataset.head (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, it is clearly visible that the DIAGNOSIS feature is taking 0s and 1s as values.\n",
    "\n",
    "0 --> Benign\n",
    "\n",
    "1 --> Malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITTING DATASET INTO DEPENDENT AND INDEPENDENT VARIABLES\n",
    "Now finally we will be splitting the updated dataset we have into two parts. The first is a collection of the independent variables and is called the MATRIX OF FEATURES. The other is a collection of the dependent variables and is known as RESPONSE FEATURE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc [:, 1:].values\n",
    "Y = dataset.iloc [:, 0].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we'll be using one of the most used feature scaling method there is, STANDARD SCALER. This method assumes your data to be normally distributed within each feature and scales them in such a way that the distribution becomes centred around 0 with a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler ()\n",
    "X_train = sc.fit_transform (X_train)\n",
    "X_test = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30575375  2.59521918  0.46246107  0.16827218  0.60422155  2.04417806\n",
      "   2.09352879  1.16366689  1.18198433  1.28429612 -0.52163603 -0.03835455\n",
      "  -0.25571081 -0.38216301 -0.77588337  1.24952899  1.41506722  0.66874898\n",
      "   0.12308074  0.80508841  0.24441187  2.73052064  0.61360382  0.04361489\n",
      "   0.42657507  3.47782867  4.41644563  1.81549702  2.10164609  3.38609913]\n",
      " [ 0.23351721 -0.05334893  0.20573083  0.08631508 -0.47424506 -0.12457556\n",
      "  -0.36621964 -0.01640861  0.26394984 -0.63317355 -0.42668937 -0.47901876\n",
      "  -0.34672558 -0.33704942 -0.54691279 -0.25816563 -0.55887941  0.005534\n",
      "  -0.66616947 -0.36984213 -0.01035708  0.08241715  0.04661672 -0.13397845\n",
      "  -0.04171878  0.30956727 -0.44003546  0.5143837   0.14721854  0.05182385]\n",
      " [ 0.15572401  0.18345881  0.11343692  0.07856238  0.15993389 -0.63952448\n",
      "  -0.18324755  0.09622333 -0.8163076  -0.52992519  0.21204267  0.02165808\n",
      "   0.14122792  0.08014965 -0.42190198 -0.78467094 -0.4022654  -0.11734193\n",
      "  -0.80990285 -0.62764173  0.55535036  0.83058615  0.46028588  0.42007226\n",
      "   0.63820786 -0.44181701  0.10469918  0.69446859  0.263409   -0.10011179]\n",
      " [-1.05562722 -0.68560261 -1.07268096 -0.91710572 -0.15389409 -1.07260771\n",
      "  -0.98593539 -1.10932235  0.28607116 -0.1184067  -0.69357579 -0.44644047\n",
      "  -0.735087   -0.57887451  0.02114151 -1.02626671 -0.73651087 -0.99874045\n",
      "  -0.61740279 -0.44365051 -1.01338447 -0.62268029 -1.05206542 -0.85127324\n",
      "  -0.1677979  -1.08156335 -1.11020629 -1.36285119 -0.3400877  -0.58500017]\n",
      " [-0.63054296 -0.43040203 -0.66038107 -0.6186268  -0.92360615 -0.94539197\n",
      "  -0.77517168 -0.66634607  0.2492023  -0.83524536 -0.70531465  0.01822879\n",
      "  -0.79322209 -0.560382    0.18598737 -0.59793558 -0.60091434 -0.51306545\n",
      "  -0.31966938 -0.73393993 -0.65028855  0.01222645 -0.66934913 -0.62691815\n",
      "   0.21043944 -0.51507536 -0.6795224  -0.34852305  0.38827039 -0.81765163]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train [:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.58502337e-01 -1.23049032e+00  2.53691428e-01 -7.21453404e-05\n",
      "   4.81009638e-01  1.55141337e+00  7.10234684e-01  3.62700248e-01\n",
      "   1.02713514e+00  1.65894019e+00  4.65809179e-01  4.86327343e-01\n",
      "   9.03655260e-01  1.62451465e-01  9.57103281e-01  1.47051757e+00\n",
      "   7.09626219e-01  6.24639667e-01  7.85280914e-01  5.58589606e-01\n",
      "   3.17700683e-02 -1.16984866e+00  1.91256286e-01 -1.34991341e-01\n",
      "  -4.62216093e-02  7.01791156e-01  2.54378520e-01 -5.73858182e-02\n",
      "  -8.68965562e-02  4.88638842e-01]\n",
      " [-2.63803596e-01 -1.54509521e-01 -2.39617537e-01 -3.36483918e-01\n",
      "   1.40147509e+00  3.63673764e-01  4.28545703e-01  6.28921185e-01\n",
      "   1.18198433e+00  7.31179866e-01 -4.28760938e-01 -5.72124078e-01\n",
      "  -4.77291260e-01 -3.49648715e-01 -1.58278149e-01 -1.36069442e-01\n",
      "  -9.48002516e-02  4.96433119e-02 -3.82552731e-01 -7.74338066e-02\n",
      "  -1.26708259e-01  3.63179927e-01 -1.35629132e-01 -2.19061193e-01\n",
      "   2.08811767e+00  1.04604055e+00  1.13135222e+00  1.41330744e+00\n",
      "   1.77388495e+00  2.02105229e+00]\n",
      " [-3.24926823e-01 -7.61473048e-01 -3.54078114e-01 -3.94352280e-01\n",
      "   2.92567891e-01 -4.93658276e-01 -3.39182524e-01 -3.87326046e-01\n",
      "  -2.85396093e-01  2.78362029e-01 -6.97028395e-01 -7.95199617e-01\n",
      "  -7.94651641e-01 -4.83363762e-01  5.51951664e-01 -3.20042439e-01\n",
      "  -2.88025320e-01 -8.11092839e-02  7.49347571e-01  3.05027801e-01\n",
      "  -5.13876829e-01 -9.16205014e-01 -5.40330636e-01 -5.12799232e-01\n",
      "   7.23761549e-01 -3.14101133e-01 -2.25576866e-01 -1.35422603e-01\n",
      "   8.72108265e-01  7.11794325e-01]\n",
      " [ 1.16425725e+00 -1.72902356e-01  1.07506698e+00  1.06564712e+00\n",
      "  -7.67054545e-01 -3.90589963e-01 -8.59139496e-02  2.38293157e-01\n",
      "  -6.87266611e-01 -1.26298859e+00 -5.30267543e-01 -1.28884641e+00\n",
      "  -5.15412627e-01 -2.54747610e-01 -1.34555699e+00 -9.19418729e-01\n",
      "  -6.00914335e-01 -8.05919757e-01 -1.24751963e+00 -9.80085579e-01\n",
      "   1.00470663e+00  1.09536279e-01  9.17346905e-01  8.79248967e-01\n",
      "  -3.97441997e-01 -6.96905440e-02  4.10928385e-01  6.37441710e-01\n",
      "   5.70359913e-01 -8.58603036e-01]\n",
      " [ 2.80748791e-01  2.40899174e+00  1.92833867e-01  1.75471117e-01\n",
      "  -9.61294499e-01 -1.14897642e+00 -5.23915164e-01 -5.48850479e-01\n",
      "   1.64403936e-01 -1.45621053e+00  1.96160680e-01  6.85226362e-01\n",
      "   6.87973223e-02  7.97432219e-02 -6.14433502e-02 -6.38266002e-01\n",
      "  -2.35820653e-01 -4.32881026e-01  1.42438108e+00 -7.45947032e-01\n",
      "   1.92254450e-01  1.79251772e+00  7.55446339e-02  7.13005458e-02\n",
      "  -7.84684989e-01 -1.01517702e+00 -5.66158704e-01 -7.33454504e-01\n",
      "   6.17182933e-01 -1.31737747e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (X_test [:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 11s 301ms/step - loss: 0.9079 - accuracy: 0.4443 - val_loss: 0.7148 - val_accuracy: 0.5594\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.6495 - accuracy: 0.6453 - val_loss: 0.5527 - val_accuracy: 0.7902\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.8054 - val_loss: 0.4514 - val_accuracy: 0.8462\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8936 - val_loss: 0.3873 - val_accuracy: 0.9161\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.9177 - val_loss: 0.3414 - val_accuracy: 0.9231\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.9411 - val_loss: 0.3057 - val_accuracy: 0.9301\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.9375 - val_loss: 0.2772 - val_accuracy: 0.9510\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2589 - accuracy: 0.9512 - val_loss: 0.2532 - val_accuracy: 0.9510\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2457 - accuracy: 0.9284 - val_loss: 0.2341 - val_accuracy: 0.9510\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9526 - val_loss: 0.2177 - val_accuracy: 0.9580\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9590 - val_loss: 0.2039 - val_accuracy: 0.9580\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9652 - val_loss: 0.1919 - val_accuracy: 0.9650\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9576 - val_loss: 0.1815 - val_accuracy: 0.9650\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9458 - val_loss: 0.1732 - val_accuracy: 0.9650\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1485 - accuracy: 0.9756 - val_loss: 0.1663 - val_accuracy: 0.9650\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9743 - val_loss: 0.1598 - val_accuracy: 0.9650\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9731 - val_loss: 0.1543 - val_accuracy: 0.9650\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9851 - val_loss: 0.1493 - val_accuracy: 0.9650\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9800 - val_loss: 0.1448 - val_accuracy: 0.9650\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9823 - val_loss: 0.1408 - val_accuracy: 0.9650\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9812 - val_loss: 0.1372 - val_accuracy: 0.9650\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9879 - val_loss: 0.1341 - val_accuracy: 0.9650\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9848 - val_loss: 0.1313 - val_accuracy: 0.9650\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9780 - val_loss: 0.1291 - val_accuracy: 0.9650\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9886 - val_loss: 0.1262 - val_accuracy: 0.9650\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9800 - val_loss: 0.1241 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0826 - accuracy: 0.9854 - val_loss: 0.1220 - val_accuracy: 0.9650\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9876 - val_loss: 0.1203 - val_accuracy: 0.9650\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9815 - val_loss: 0.1188 - val_accuracy: 0.9650\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9849 - val_loss: 0.1172 - val_accuracy: 0.9650\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9920 - val_loss: 0.1158 - val_accuracy: 0.9650\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9852 - val_loss: 0.1151 - val_accuracy: 0.9650\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9844 - val_loss: 0.1140 - val_accuracy: 0.9650\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9850 - val_loss: 0.1132 - val_accuracy: 0.9650\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9801 - val_loss: 0.1125 - val_accuracy: 0.9650\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9958 - val_loss: 0.1118 - val_accuracy: 0.9650\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9886 - val_loss: 0.1111 - val_accuracy: 0.9650\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9856 - val_loss: 0.1106 - val_accuracy: 0.9650\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9770 - val_loss: 0.1100 - val_accuracy: 0.9650\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9865 - val_loss: 0.1096 - val_accuracy: 0.9650\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9889 - val_loss: 0.1091 - val_accuracy: 0.9650\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9950 - val_loss: 0.1085 - val_accuracy: 0.9580\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9966 - val_loss: 0.1083 - val_accuracy: 0.9580\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9932 - val_loss: 0.1077 - val_accuracy: 0.9580\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9945 - val_loss: 0.1072 - val_accuracy: 0.9580\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9859 - val_loss: 0.1070 - val_accuracy: 0.9580\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9795 - val_loss: 0.1068 - val_accuracy: 0.9580\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9884 - val_loss: 0.1063 - val_accuracy: 0.9580\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9880 - val_loss: 0.1059 - val_accuracy: 0.9580\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9915 - val_loss: 0.1051 - val_accuracy: 0.9580\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9943 - val_loss: 0.1048 - val_accuracy: 0.9580\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9926 - val_loss: 0.1038 - val_accuracy: 0.9580\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9920 - val_loss: 0.1031 - val_accuracy: 0.9580\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9861 - val_loss: 0.1025 - val_accuracy: 0.9580\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9828 - val_loss: 0.1019 - val_accuracy: 0.9580\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.1022 - val_accuracy: 0.9580\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9878 - val_loss: 0.1011 - val_accuracy: 0.9650\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9844 - val_loss: 0.1006 - val_accuracy: 0.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9903 - val_loss: 0.1006 - val_accuracy: 0.9650\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9956 - val_loss: 0.1006 - val_accuracy: 0.9580\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 0.9955 - val_loss: 0.0999 - val_accuracy: 0.9650\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9886 - val_loss: 0.0992 - val_accuracy: 0.9650\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9799 - val_loss: 0.0991 - val_accuracy: 0.9650\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.0988 - val_accuracy: 0.9650\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9843 - val_loss: 0.0984 - val_accuracy: 0.9650\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9963 - val_loss: 0.0983 - val_accuracy: 0.9650\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9956 - val_loss: 0.0977 - val_accuracy: 0.9650\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9954 - val_loss: 0.0964 - val_accuracy: 0.9650\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9805 - val_loss: 0.0954 - val_accuracy: 0.9650\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9887 - val_loss: 0.0946 - val_accuracy: 0.9650\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9881 - val_loss: 0.0942 - val_accuracy: 0.9650\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9913 - val_loss: 0.0937 - val_accuracy: 0.9650\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9942 - val_loss: 0.0935 - val_accuracy: 0.9650\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9921 - val_loss: 0.0928 - val_accuracy: 0.9650\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9811 - val_loss: 0.0911 - val_accuracy: 0.9720\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9914 - val_loss: 0.0904 - val_accuracy: 0.9720\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9891 - val_loss: 0.0891 - val_accuracy: 0.9720\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.0889 - val_accuracy: 0.9720\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9930 - val_loss: 0.0883 - val_accuracy: 0.9720\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9903 - val_loss: 0.0878 - val_accuracy: 0.9720\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0880 - val_accuracy: 0.9720\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9939 - val_loss: 0.0873 - val_accuracy: 0.9720\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9907 - val_loss: 0.0870 - val_accuracy: 0.9720\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0873 - val_accuracy: 0.9720\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9917 - val_loss: 0.0871 - val_accuracy: 0.9720\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9967 - val_loss: 0.0873 - val_accuracy: 0.9720\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 0.0870 - val_accuracy: 0.9720\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9841 - val_loss: 0.0870 - val_accuracy: 0.9720\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 0.0869 - val_accuracy: 0.9720\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9971 - val_loss: 0.0872 - val_accuracy: 0.9720\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0868 - val_accuracy: 0.9720\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.9878 - val_loss: 0.0866 - val_accuracy: 0.9720\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9927 - val_loss: 0.0864 - val_accuracy: 0.9720\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9944 - val_loss: 0.0867 - val_accuracy: 0.9720\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9979 - val_loss: 0.0867 - val_accuracy: 0.9720\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.0865 - val_accuracy: 0.9720\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9920 - val_loss: 0.0870 - val_accuracy: 0.9720\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0294 - accuracy: 0.9932 - val_loss: 0.0873 - val_accuracy: 0.9720\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9946 - val_loss: 0.0869 - val_accuracy: 0.9720\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9921 - val_loss: 0.0869 - val_accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "# Training the ANN on the training set\n",
    "history=ann.fit(X_train, Y_train, validation_data = (X_test,Y_test),batch_size = 16, epochs = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.9)\n",
    "np.set_printoptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = metrics.classification_report(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        88\n",
      "           1       1.00      0.93      0.96        55\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.98      0.96      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[88  0]\n",
      " [ 4 51]]\n",
      "\n",
      "Accuracy\n",
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# Making the confusion matrix, calculating accuracy_score \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "mylist = []\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# accuracy\n",
    "ac_ann = accuracy_score(Y_test,y_pred)\n",
    "print(\"Accuracy\")\n",
    "print(ac_ann)\n",
    "mylist.append(ac_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
